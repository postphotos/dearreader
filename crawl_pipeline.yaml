# DearReader AI Configuration
# Simplified configuration for AI providers and tasks

ai_providers:
  # OpenRout# Pipeline routing configuration for URL-based processing
pipeline_routing:
  # Default pipeline for regular requests
  default: "default_html"

  # URL route mappings to pipelines
  routes:
    "/default_html": "default_html"
    "/default_html_json": "default_html_json"
    "/default_pdf": "default_pdf"
    "/default_html_ai": "default_html_ai"
    "/default_pdf_ai": "default_pdf_ai"
    "/json/": "default_html_json"  # Legacy support for /json/ URLs
    "/": "default_html"  # Default for root URLs (makes /https://example.com work)

  # Quick AI Enhancement Examples:
  # To enable AI in default_html pipeline, change ai_enhancement.enabled to true:
  #   ai_enhancement:
  #     enabled: true
  #     task: "content_classification"
  #     condition: "always"
  #
  # To enable AI in default_pdf pipeline, change:
  #   ai_enhancement:
  #     enabled: true
  #     task: "parse_pdf"
  #     condition: "low_ocr_confidence"

  # Pipeline definitions for URL-based processingAPI key required)
  deepseek/deepseek-r1:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "deepseek/deepseek-r1:free"
    api_key: "${OPENROUTER_API_KEY}"

  meta-llama/llama-3.3-70b-instruct:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "meta-llama/llama-3.3-70b-instruct:free"
    api_key: "${OPENROUTER_API_KEY}"

  qwen/qwen-2.5-72b-instruct:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "qwen/qwen-2.5-72b-instruct:free"
    api_key: "${OPENROUTER_API_KEY}"

  google/gemma-3-27b-it:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "google/gemma-3-27b-it:free"
    api_key: "${OPENROUTER_API_KEY}"

  mistralai/mistral-small-3.1-24b-instruct:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "mistralai/mistral-small-3.1-24b-instruct:free"
    api_key: "${OPENROUTER_API_KEY}"

  # Provider aliases for tests (using your actual free APIs)
  openrouter-big:
    base_url: "https://openrouter.ai/api/v1"
    model: "deepseek/deepseek-r1:free"
    api_key: "${OPENROUTER_API_KEY}"
    temperature: 0.1
    max_tokens: 4096
    rpm_limit: 10

  openrouter-small:
    base_url: "https://openrouter.ai/api/v1"
    model: "google/gemma-3-27b-it:free"
    api_key: "${OPENROUTER_API_KEY}"
    temperature: 0.2
    max_tokens: 2048
    rpm_limit: 20

ai_tasks:
  parse_pdf: "openrouter-big"
  parse_pdf_backup: "openrouter-small"
  validate_format: "openrouter-small"
  validate_format_backup: "openrouter-big"
  edit_crawl: "openrouter-big"
  edit_crawl_backup: "openrouter-small"
  general_chat: "openrouter-small"
  general_chat_backup: "openrouter-big"
  code_analysis: "openrouter-big"
  code_analysis_backup: "openrouter-small"
  ocr_processing: "openrouter-small"
  ocr_processing_backup: "openrouter-big"
  sentiment_analysis: "openrouter-small"
  sentiment_analysis_backup: "openrouter-big"
  content_classification: "openrouter-small"
  content_classification_backup: "openrouter-big"
  default: "openrouter-small"
  default_backup: "openrouter-big"

# Task pipelines - allow tasks to nest other tasks
ai_task_pipelines:
  # Complex PDF processing pipeline
  process_pdf_comprehensive:
    - task: parse_pdf
      description: "Extract raw text from PDF"
    - task: validate_format
      description: "Validate extracted content format"
      depends_on: parse_pdf
    - task: content_classification
      description: "Classify content type and structure"
      depends_on: validate_format

  # OCR-enhanced PDF processing
  process_pdf_with_ocr:
    - task: parse_pdf
      description: "Extract text from PDF"
    - task: ocr_processing
      description: "Apply OCR for better text extraction"
      depends_on: parse_pdf
      condition: "low_confidence_text"
    - task: validate_format
      description: "Validate final content"
      depends_on: [parse_pdf, ocr_processing]

  # Content analysis pipeline
  analyze_content:
    - task: content_classification
      description: "Determine content type"
    - task: sentiment_analysis
      description: "Analyze sentiment and tone"
      depends_on: content_classification
    - task: general_chat
      description: "Generate insights and summary"
      depends_on: [content_classification, sentiment_analysis]

  # Code review pipeline
  review_code:
    - task: code_analysis
      description: "Analyze code structure and quality"
    - task: general_chat
      description: "Generate review comments and suggestions"
      depends_on: code_analysis

# Pipeline routing configuration for URL-based processing
pipeline_routing:
  # Default pipeline for regular requests
  default: "default_html"

  # URL route mappings to pipelines
  routes:
    "/default_html": "default_html"
    "/default_html_json": "default_html_json"
    "/default_pdf": "default_pdf"
    "/default_html_ai": "default_html_ai"
    "/default_pdf_ai": "default_pdf_ai"
    "/json/": "default_html_json"  # Legacy support for /json/ URLs
    "/": "default_html"  # Default for root URLs (makes /https://example.com work) (makes /https://example.com work)

  # Pipeline definitions for URL-based processing
  pipelines:
    default_html:
      name: "Default HTML Processing Pipeline"
      description: "Default pipeline for HTML content that renders markdown"
      content_type: "html"
      ai_required: false
      stages:
        - type: "crawl"
          name: "crawl_html"
          description: "Fetch HTML content from URL"
          config:
            timeout_ms: 30000
            wait_for_network_idle: true
            respect_robots_txt: true
            user_agent: "DearReader-Bot/1.0"
        - type: "text_extract"
          name: "extract_text"
          description: "Extract clean text from HTML using readability"
          config:
            use_readability: true
            remove_selectors: ["script", "style", "noscript", "link", "meta", "textarea", "select"]
            target_selectors: ["article", "main", ".content", "#content"]
            min_content_length: 100
            max_content_length: 1000000
        - type: "content_filter"
          name: "filter_content"
          description: "Filter and clean extracted content"
          config:
            remove_duplicates: true
            normalize_whitespace: true
            remove_empty_lines: true
            trim_whitespace: true
            min_line_length: 10
        - type: "markdown_format"
          name: "convert_markdown"
          description: "Convert HTML to markdown format"
          config:
            code_block_style: "fenced"
            heading_style: "atx"
            bullet_list_marker: "-"
            emphasis_delimiter: "_"
            strong_delimiter: "**"
            link_style: "inlined"
            link_reference_style: "full"
            img_data_url_to_object_url: true
            keep_img_data_url: false
            generate_alt_text: false
          ai_enhancement:
            enabled: false
            task: "content_classification"
            condition: "low_quality_content"
            fallback_task: "general_chat"
      expected_fields: ["title", "content", "markdown_content", "links", "metadata", "timestamp"]
      expected_output_format: "markdown"
      render_markdown: true

    default_html_json:
      name: "Default HTML to JSON Processing Pipeline"
      description: "Default pipeline for HTML content that renders markdown into JSON"
      content_type: "html"
      ai_required: false
      stages:
        - type: "crawl"
          name: "crawl_html"
          description: "Fetch HTML content from URL"
          config:
            timeout_ms: 30000
            wait_for_network_idle: true
            respect_robots_txt: true
            user_agent: "DearReader-Bot/1.0"
        - type: "text_extract"
          name: "extract_text"
          description: "Extract clean text from HTML using readability"
          config:
            use_readability: true
            remove_selectors: ["script", "style", "noscript", "link", "meta", "textarea", "select"]
            target_selectors: ["article", "main", ".content", "#content"]
            min_content_length: 100
            max_content_length: 1000000
        - type: "content_filter"
          name: "filter_content"
          description: "Filter and clean extracted content"
          config:
            remove_duplicates: true
            normalize_whitespace: true
            remove_empty_lines: true
            trim_whitespace: true
            min_line_length: 10
        - type: "markdown_format"
          name: "convert_markdown"
          description: "Convert HTML to markdown format"
          config:
            code_block_style: "fenced"
            heading_style: "atx"
            bullet_list_marker: "-"
            emphasis_delimiter: "_"
            strong_delimiter: "**"
            link_style: "inlined"
            link_reference_style: "full"
            img_data_url_to_object_url: true
            keep_img_data_url: false
            generate_alt_text: false
          ai_enhancement:
            enabled: false
            task: "sentiment_analysis"
            condition: "content_too_short"
            fallback_task: "general_chat"
        - type: "json_format"
          name: "format_json"
          description: "Format content as JSON response"
          config:
            include_metadata: true
            include_links: true
            include_images: true
            include_timestamps: true
            include_processing_stats: true
            pretty_print: false
            calculate_token_usage: true
      expected_fields: ["title", "content", "markdown_content", "links", "metadata", "timestamp"]
      expected_output_format: "json"
      render_markdown: true
      convert_to_json: true

    default_pdf:
      name: "Default PDF Processing Pipeline"
      description: "Default pipeline for PDF content using Tesseract OCR"
      content_type: "pdf"
      ai_required: false
      stages:
        - type: "crawl"
          name: "crawl_pdf"
          description: "Fetch PDF content from URL"
          config:
            timeout_ms: 30000
            respect_robots_txt: true
            user_agent: "DearReader-Bot/1.0"
            enable_pdf_parsing: true
            max_file_size_mb: 50
        - type: "pdf_extract"
          name: "extract_pdf_text"
          description: "Extract text from PDF using OCR when needed"
          config:
            use_tesseract_ocr: true
            ocr_languages: ["eng"]
            extract_metadata: true
            max_pages: 100
            processing_timeout_seconds: 30
            confidence_threshold: 0.7
            enable_ai_fallback: false
          ai_enhancement:
            enabled: false
            task: "parse_pdf"
            condition: "low_ocr_confidence"
            fallback_task: "ocr_processing"
        - type: "content_filter"
          name: "filter_pdf_content"
          description: "Filter and clean extracted PDF text"
          config:
            remove_duplicates: true
            normalize_whitespace: true
            remove_empty_lines: true
            trim_whitespace: true
            min_line_length: 5
            remove_page_numbers: true
            remove_headers_footers: true
        - type: "json_format"
          name: "format_pdf_json"
          description: "Format PDF content as JSON response"
          config:
            include_metadata: true
            include_ocr_quality: true
            include_processing_stats: true
            include_timestamps: true
            pretty_print: false
            calculate_token_usage: true
      expected_fields: ["title", "content", "extracted_text", "ocr_quality", "metadata", "timestamp"]
      expected_output_format: "json"
      use_tesseract: true
      enable_ai_fallback: false

    # AI-enhanced pipeline variants
    default_html_ai:
      name: "AI-Enhanced HTML Processing Pipeline"
      description: "HTML pipeline with AI content classification and enhancement"
      content_type: "html"
      ai_required: true
      stages:
        - type: "crawl"
          name: "crawl_html"
          description: "Fetch HTML content from URL"
          config:
            timeout_ms: 30000
            wait_for_network_idle: true
            respect_robots_txt: true
            user_agent: "DearReader-Bot/1.0"
        - type: "text_extract"
          name: "extract_text"
          description: "Extract clean text from HTML using readability"
          config:
            use_readability: true
            remove_selectors: ["script", "style", "noscript", "link", "meta", "textarea", "select"]
            target_selectors: ["article", "main", ".content", "#content"]
            min_content_length: 100
            max_content_length: 1000000
        - type: "content_filter"
          name: "filter_content"
          description: "Filter and clean extracted content"
          config:
            remove_duplicates: true
            normalize_whitespace: true
            remove_empty_lines: true
            trim_whitespace: true
            min_line_length: 10
        - type: "ai_process"
          name: "ai_content_enhancement"
          description: "Enhance content with AI processing"
          config:
            primary_task: "content_classification"
            secondary_tasks: ["sentiment_analysis", "general_chat"]
            enhancement_mode: "comprehensive"
            max_tokens: 2048
        - type: "markdown_format"
          name: "convert_markdown"
          description: "Convert HTML to markdown format"
          config:
            code_block_style: "fenced"
            heading_style: "atx"
            bullet_list_marker: "-"
            emphasis_delimiter: "_"
            strong_delimiter: "**"
            link_style: "inlined"
            link_reference_style: "full"
            img_data_url_to_object_url: true
            keep_img_data_url: false
            generate_alt_text: true
      expected_fields: ["title", "content", "markdown_content", "links", "metadata", "timestamp", "ai_insights", "sentiment", "classification"]
      expected_output_format: "markdown"
      render_markdown: true

    default_pdf_ai:
      name: "AI-Enhanced PDF Processing Pipeline"
      description: "PDF pipeline with AI parsing and OCR enhancement"
      content_type: "pdf"
      ai_required: true
      stages:
        - type: "crawl"
          name: "crawl_pdf"
          description: "Fetch PDF content from URL"
          config:
            timeout_ms: 30000
            respect_robots_txt: true
            user_agent: "DearReader-Bot/1.0"
            enable_pdf_parsing: true
            max_file_size_mb: 50
        - type: "pdf_extract"
          name: "extract_pdf_text"
          description: "Extract text from PDF using OCR when needed"
          config:
            use_tesseract_ocr: true
            ocr_languages: ["eng"]
            extract_metadata: true
            max_pages: 100
            processing_timeout_seconds: 30
            confidence_threshold: 0.7
            enable_ai_fallback: true
          ai_enhancement:
            enabled: true
            task: "parse_pdf"
            condition: "low_ocr_confidence"
            fallback_task: "ocr_processing"
        - type: "ai_process"
          name: "ai_pdf_analysis"
          description: "Analyze PDF content with AI"
          config:
            primary_task: "parse_pdf"
            secondary_tasks: ["content_classification", "sentiment_analysis"]
            enhancement_mode: "document_analysis"
            max_tokens: 4096
        - type: "content_filter"
          name: "filter_pdf_content"
          description: "Filter and clean extracted PDF text"
          config:
            remove_duplicates: true
            normalize_whitespace: true
            remove_empty_lines: true
            trim_whitespace: true
            min_line_length: 5
            remove_page_numbers: true
            remove_headers_footers: true
        - type: "json_format"
          name: "format_pdf_json"
          description: "Format PDF content as JSON response"
          config:
            include_metadata: true
            include_ocr_quality: true
            include_processing_stats: true
            include_timestamps: true
            include_ai_insights: true
            pretty_print: false
            calculate_token_usage: true
      expected_fields: ["title", "content", "extracted_text", "ocr_quality", "metadata", "timestamp", "ai_analysis", "classification"]
      expected_output_format: "json"
      use_tesseract: true
      enable_ai_fallback: true

# Pipeline test definitions
pipeline_tests:
  # Stage-level tests for individual pipeline components
  stage_tests:
    crawl:
      name: "Web Crawling Stage"
      tests:
        - name: "basic_html_crawl"
          test_url: "https://example.com/test.html"
          expected_content_type: "text/html"
          expected_selectors: ["h1", "p"]
        - name: "json_api_crawl"
          test_url: "https://api.example.com/data.json"
          expected_content_type: "application/json"

    text_extract:
      name: "Text Extraction Stage"
      tests:
        - name: "basic_html_extraction"
          test_html: "<html><body><h1>Test Article</h1><p>This is test content.</p><script>console.log('test');</script></body></html>"
          expected_text_contains: ["Test Article", "This is test content"]
          expected_text_excludes: ["console.log"]
        - name: "complex_html_extraction"
          test_html: "<html><body><nav>Navigation</nav><h1>Main Article</h1><p>Content here.</p><footer>Footer</footer></body></html>"
          expected_text_contains: ["Main Article", "Content here"]
          expected_text_excludes: ["Navigation", "Footer"]

    content_filter:
      name: "Content Filtering Stage"
      tests:
        - name: "duplicate_removal"
          test_content: "This is duplicate text. This is duplicate text. Unique content here."
          remove_duplicates: true
          expected_content: "This is duplicate text. Unique content here."
        - name: "content_length_filter"
          test_content: "Short text"
          min_length: 20
          expected_filtered: true

    json_format:
      name: "JSON Formatting Stage"
      tests:
        - name: "basic_json_formatting"
          test_data:
            title: "Test Article"
            content: "Test content"
          expected_fields: ["success", "timestamp", "data", "metadata"]
        - name: "comprehensive_json_formatting"
          test_data:
            title: "Test Article"
            content: "Test content"
            url: "https://example.com"
            metadata:
              author: "Test Author"
          include_url: true
          include_processing_stats: true
          expected_fields: ["success", "timestamp", "data", "metadata", "url", "processing_stats"]
          expected_nested_fields: ["metadata.author", "processing_stats.processing_time_ms"]

    pdf_extract:
      name: "PDF Text Extraction Stage"
      tests:
        - name: "valid_pdf_extraction"
          test_pdf_content: "Mock PDF content with Hello World text"
          expected_text_contains: ["Hello World"]
        - name: "empty_pdf_handling"
          test_pdf_content: ""
          expected_error: "Empty buffer"

  # End-to-end pipeline tests
  pipeline_tests:
    default_html:
      name: "Default HTML Processing Pipeline"
      description: "Default pipeline for HTML content that renders markdown"
      expected_fields: ["title", "content", "markdown_content", "links", "metadata", "timestamp"]
      expected_output_format: "markdown"
      render_markdown: true

    default_html_json:
      name: "Default HTML to JSON Processing Pipeline"
      description: "Default pipeline for HTML content that renders markdown into JSON"
      expected_fields: ["title", "content", "markdown_content", "links", "metadata", "timestamp"]
      expected_output_format: "json"
      render_markdown: true
      convert_to_json: true

    default_pdf:
      name: "Default PDF Processing Pipeline"
      description: "Default pipeline for PDF content using Tesseract OCR"
      expected_fields: ["title", "content", "extracted_text", "ocr_quality", "metadata", "timestamp"]
      expected_output_format: "json"
      use_tesseract: true
      enable_ai_fallback: false

    html_default:
      name: "HTML Content Processing Pipeline"
      description: "Complete pipeline for HTML content processing"
      expected_fields: ["title", "content", "links", "metadata", "timestamp"]
      expected_output_format: "json"

    pdf_default:
      name: "PDF Content Processing Pipeline"
      description: "Complete pipeline for PDF content processing"
      expected_fields: ["title", "content", "extracted_text", "quality_assessment", "metadata", "timestamp"]
      expected_output_format: "json"

    html_enhanced:
      name: "Enhanced HTML Processing Pipeline"
      description: "HTML pipeline with additional processing steps"
      expected_fields: ["title", "content", "links", "metadata", "timestamp", "categorization", "markdown_content"]
      expected_output_format: "json"

  # AI task tests (mocked to avoid API calls)
  ai_task_tests:
    parse_pdf:
      name: "PDF Parsing Task"
      mock_response: "Mock PDF parsing result"
      validate_task_routing: true
      expected_provider: "openrouter-big"
      expected_response_format: "text"

    validate_format:
      name: "Content Format Validation Task"
      mock_response: "Mock format validation result"
      validate_task_routing: true
      expected_provider: "openrouter-small"
      expected_response_format: "text"

    general_chat:
      name: "General Chat Task"
      mock_response: "Mock chat response"
      validate_task_routing: true
      expected_provider: "openrouter-small"
      expected_response_format: "text"

    code_analysis:
      name: "Code Analysis Task"
      mock_response: "Mock code analysis result"
      validate_task_routing: true
      expected_provider: "openrouter-big"
      expected_response_format: "text"
