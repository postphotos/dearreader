# DearReader AI Configuration
# Simplified configuration for AI providers and tasks

ai_providers:
  # OpenRouter free models (API key required)
  deepseek/deepseek-r1:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "deepseek/deepseek-r1:free"
    api_key: "${OPENROUTER_API_KEY}"

  meta-llama/llama-3.3-70b-instruct:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "meta-llama/llama-3.3-70b-instruct:free"
    api_key: "${OPENROUTER_API_KEY}"

  qwen/qwen-2.5-72b-instruct:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "qwen/qwen-2.5-72b-instruct:free"
    api_key: "${OPENROUTER_API_KEY}"

  google/gemma-3-27b-it:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "google/gemma-3-27b-it:free"
    api_key: "${OPENROUTER_API_KEY}"

  mistralai/mistral-small-3.1-24b-instruct:free:
    base_url: "https://openrouter.ai/api/v1"
    model: "mistralai/mistral-small-3.1-24b-instruct:free"
    api_key: "${OPENROUTER_API_KEY}"

  # Provider aliases for tests (using your actual free APIs)
  openrouter-big:
    base_url: "https://openrouter.ai/api/v1"
    model: "deepseek/deepseek-r1:free"
    api_key: "${OPENROUTER_API_KEY}"
    temperature: 0.1
    max_tokens: 4096
    rpm_limit: 10

  openrouter-small:
    base_url: "https://openrouter.ai/api/v1"
    model: "google/gemma-3-27b-it:free"
    api_key: "${OPENROUTER_API_KEY}"
    temperature: 0.2
    max_tokens: 2048
    rpm_limit: 20

ai_tasks:
  parse_pdf: "openrouter-big"
  parse_pdf_backup: "openrouter-small"
  validate_format: "openrouter-small"
  validate_format_backup: "openrouter-big"
  edit_crawl: "openrouter-big"
  edit_crawl_backup: "openrouter-small"
  general_chat: "openrouter-small"
  general_chat_backup: "openrouter-big"
  code_analysis: "openrouter-big"
  code_analysis_backup: "openrouter-small"
  ocr_processing: "openrouter-small"
  ocr_processing_backup: "openrouter-big"
  sentiment_analysis: "openrouter-small"
  sentiment_analysis_backup: "openrouter-big"
  content_classification: "openrouter-small"
  content_classification_backup: "openrouter-big"
  default: "openrouter-small"
  default_backup: "openrouter-big"

# Task pipelines - allow tasks to nest other tasks
ai_task_pipelines:
  # Complex PDF processing pipeline
  process_pdf_comprehensive:
    - task: parse_pdf
      description: "Extract raw text from PDF"
    - task: validate_format
      description: "Validate extracted content format"
      depends_on: parse_pdf
    - task: content_classification
      description: "Classify content type and structure"
      depends_on: validate_format

  # OCR-enhanced PDF processing
  process_pdf_with_ocr:
    - task: parse_pdf
      description: "Extract text from PDF"
    - task: ocr_processing
      description: "Apply OCR for better text extraction"
      depends_on: parse_pdf
      condition: "low_confidence_text"
    - task: validate_format
      description: "Validate final content"
      depends_on: [parse_pdf, ocr_processing]

  # Content analysis pipeline
  analyze_content:
    - task: content_classification
      description: "Determine content type"
    - task: sentiment_analysis
      description: "Analyze sentiment and tone"
      depends_on: content_classification
    - task: general_chat
      description: "Generate insights and summary"
      depends_on: [content_classification, sentiment_analysis]

  # Code review pipeline
  review_code:
    - task: code_analysis
      description: "Analyze code structure and quality"
    - task: general_chat
      description: "Generate review comments and suggestions"
      depends_on: code_analysis

# Pipeline test definitions
pipeline_tests:
  # Stage-level tests for individual pipeline components
  stage_tests:
    crawl:
      name: "Web Crawling Stage"
      tests:
        - name: "basic_html_crawl"
          test_url: "https://example.com/test.html"
          expected_content_type: "text/html"
          expected_selectors: ["h1", "p"]
        - name: "json_api_crawl"
          test_url: "https://api.example.com/data.json"
          expected_content_type: "application/json"

    text_extract:
      name: "Text Extraction Stage"
      tests:
        - name: "basic_html_extraction"
          test_html: "<html><body><h1>Test Article</h1><p>This is test content.</p><script>console.log('test');</script></body></html>"
          expected_text_contains: ["Test Article", "This is test content"]
          expected_text_excludes: ["console.log"]
        - name: "complex_html_extraction"
          test_html: "<html><body><nav>Navigation</nav><h1>Main Article</h1><p>Content here.</p><footer>Footer</footer></body></html>"
          expected_text_contains: ["Main Article", "Content here"]
          expected_text_excludes: ["Navigation", "Footer"]

    content_filter:
      name: "Content Filtering Stage"
      tests:
        - name: "duplicate_removal"
          test_content: "This is duplicate text. This is duplicate text. Unique content here."
          remove_duplicates: true
          expected_content: "This is duplicate text. Unique content here."
        - name: "content_length_filter"
          test_content: "Short text"
          min_length: 20
          expected_filtered: true

    json_format:
      name: "JSON Formatting Stage"
      tests:
        - name: "basic_json_formatting"
          test_data:
            title: "Test Article"
            content: "Test content"
          expected_fields: ["success", "timestamp", "data", "metadata"]
        - name: "comprehensive_json_formatting"
          test_data:
            title: "Test Article"
            content: "Test content"
            url: "https://example.com"
            metadata:
              author: "Test Author"
          include_url: true
          include_processing_stats: true
          expected_fields: ["success", "timestamp", "data", "metadata", "url", "processing_stats"]
          expected_nested_fields: ["metadata.author", "processing_stats.processing_time_ms"]

    pdf_extract:
      name: "PDF Text Extraction Stage"
      tests:
        - name: "valid_pdf_extraction"
          test_pdf_content: "Mock PDF content with Hello World text"
          expected_text_contains: ["Hello World"]
        - name: "empty_pdf_handling"
          test_pdf_content: ""
          expected_error: "Empty buffer"

  # End-to-end pipeline tests
  pipeline_tests:
    html_default:
      name: "HTML Content Processing Pipeline"
      description: "Complete pipeline for HTML content processing"
      expected_fields: ["title", "content", "links", "metadata", "timestamp"]
      expected_output_format: "json"

    pdf_default:
      name: "PDF Content Processing Pipeline"
      description: "Complete pipeline for PDF content processing"
      expected_fields: ["title", "content", "extracted_text", "quality_assessment", "metadata", "timestamp"]
      expected_output_format: "json"

    html_enhanced:
      name: "Enhanced HTML Processing Pipeline"
      description: "HTML pipeline with additional processing steps"
      expected_fields: ["title", "content", "links", "metadata", "timestamp", "categorization", "markdown_content"]
      expected_output_format: "json"

  # AI task tests (mocked to avoid API calls)
  ai_task_tests:
    parse_pdf:
      name: "PDF Parsing Task"
      mock_response: "Mock PDF parsing result"
      validate_task_routing: true
      expected_provider: "openrouter-big"
      expected_response_format: "text"

    validate_format:
      name: "Content Format Validation Task"
      mock_response: "Mock format validation result"
      validate_task_routing: true
      expected_provider: "openrouter-small"
      expected_response_format: "text"

    general_chat:
      name: "General Chat Task"
      mock_response: "Mock chat response"
      validate_task_routing: true
      expected_provider: "openrouter-small"
      expected_response_format: "text"

    code_analysis:
      name: "Code Analysis Task"
      mock_response: "Mock code analysis result"
      validate_task_routing: true
      expected_provider: "openrouter-big"
      expected_response_format: "text"
