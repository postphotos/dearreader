#!/bin/bash

# DearReader - Unified Project Manager
# A delightful CLI for managing the DearReader web crawler

set -e

# Get the directory where this script is located and navigate to project root
SCRIPT_DIR="$(dirname "$(readlink -f "${BASH_SOURCE[0]}")")"
PROJECT_ROOT="$SCRIPT_DIR"
cd "$PROJECT_ROOT"

# Global variable for uv usage
USE_UV=false

# Color and formatting constants
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
WHITE='\033[1;37m'
BOLD='\033[1m'
NC='\033[0m' # No Color

# Emoji constants
ROCKET="üöÄ"
GEAR="‚öôÔ∏è"
CHECK="‚úÖ"
CROSS="‚ùå"
WARNING="‚ö†Ô∏è"
INFO="‚ÑπÔ∏è"
BOOK="üìö"
DOCKER="üê≥"
PYTHON="üêç"
NODE="üü¢"
TEST="üß™"
STOP="üõë"
SPARKLES="‚ú®"
HEART="‚ù§Ô∏è"

# Logging functions with colors and emojis
log_info() {
    echo -e "${BLUE}${INFO}${NC} $1"
}

log_success() {
    echo -e "${GREEN}${CHECK}${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}${WARNING}${NC} $1"
}

log_error() {
    echo -e "${RED}${CROSS}${NC} $1"
}

log_header() {
    echo -e "\n${MAGENTA}${BOLD}$1${NC}"
    echo -e "${MAGENTA}$(printf '%.0s=' {1..50})${NC}"
}

log_subheader() {
    echo -e "${CYAN}${BOLD}$1${NC}"
}

# Show beautiful help
show_help() {
    cat << 'EOF'

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                     üìö DearReader CLI                       ‚ïë
‚ïë              Web Content Extraction Made Simple             ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

USAGE:
    ./dearreader <command> [subcommand] [options]

COMMANDS:
    setup           üèóÔ∏è  Set up development environment
    dev             üöÄ  Start development environment
    test            üß™  Run tests (js, python, e2e, pipeline, or all) - defaults to all
    run             ‚ñ∂Ô∏è   Start services (dev/prod)
    stop            üõë  Stop all services
    status          üìä  Show system status
    logs            üìù  Show service logs
    clean           üßπ  Clean up containers and volumes
    migration       üìã  Show migration status and tips
    task            üìã  Manage pipeline tasks (list, status, enable, disable)

OPTIONS:
    --verbose, -v   Show detailed output
    --force, -f     Continue despite errors
    --follow, -F    Follow logs in real-time

EXAMPLES:
    ./dearreader setup              # First-time setup
    ./dearreader dev                # Start development
    ./dearreader test               # Run all tests (default)
    ./dearreader test e2e           # Run end-to-end tests only
    ./dearreader test js            # Run JavaScript tests only
    ./dearreader test python        # Run Python tests only
    ./dearreader test pipeline      # Run pipeline tests only
    ./dearreader run prod           # Start production
    ./dearreader status             # Check system status
    ./dearreader api test           # Test API endpoints
    ./dearreader task list          # List all available pipeline tasks
    ./dearreader task status        # Show task status (enabled/disabled)
    ./dearreader task enable <task> # Enable a specific task
    ./dearreader task disable <task># Disable a specific task

QUICK START:
    1. ./scripts/quickstart.sh    # 1-click setup (fastest!)
    2. ./dearreader setup         # Manual setup
    3. ./dearreader dev           # Start development
    4. Open http://localhost:3001

EOF
}

# Check if Docker is available
check_docker() {
    if ! command -v docker >/dev/null 2>&1; then
        log_error "Docker is not installed or not in PATH"
        echo "Please install Docker: https://www.docker.com/get-started"
        exit 1
    fi

    if ! docker version >/dev/null 2>&1; then
        log_error "Docker daemon is not running"
        echo "Please start Docker and try again"
        exit 1
    fi

    if ! command -v docker-compose >/dev/null 2>&1; then
        log_error "Docker Compose is not installed"
        echo "Please install Docker Compose"
        exit 1
    fi
}

# Cross-platform command execution with better feedback
run_cmd() {
    local cmd="$1"
    local description="$2"
    local show_output="${3:-false}"

    if [ "$VERBOSE" = true ] || [ "$show_output" = true ]; then
        log_info "$description..."
        echo -e "${CYAN}  ‚îî‚îÄ ${cmd}${NC}"
        eval "$cmd"
    else
        log_info "$description..."
        if ! eval "$cmd" >/dev/null 2>&1; then
            log_error "Command failed: $cmd"
            return 1
        fi
    fi
}

# Setup command - comprehensive environment setup
cmd_setup() {
    log_header "${ROCKET} Setting up DearReader Environment"

    # Pre-flight checks
    log_subheader "Pre-flight Checks"

    # Check internet connectivity (cloud-friendly)
    if ! curl -s --connect-timeout 5 --max-time 10 https://www.google.com >/dev/null 2>&1 && \
       ! curl -s --connect-timeout 5 --max-time 10 https://www.cloudflare.com >/dev/null 2>&1 && \
       ! ping -c 1 -W 2 8.8.8.8 >/dev/null 2>&1; then
        log_error "No internet connection detected. Please check your network."
        log_info "Note: Some cloud environments block ICMP ping but allow HTTP"
        exit 1
    fi
    log_success "Internet connection verified"

    # Check available disk space (need at least 2GB)
    if [[ "$OSTYPE" != "msys" && "$OSTYPE" != "win32" ]]; then
        local available_space=$(df -BG . | tail -1 | awk '{print $4}' | sed 's/G.*//')
        if [ "$available_space" -lt 2 ]; then
            log_error "Insufficient disk space. Need at least 2GB free."
            exit 1
        fi
        log_success "Sufficient disk space available"
    fi

    # Check prerequisites
    log_subheader "Checking Prerequisites"
    check_docker

    # Check for Node.js and npm
    if ! command -v node >/dev/null 2>&1; then
        log_error "Node.js is not installed. Please install Node.js 18+ from https://nodejs.org"
        exit 1
    fi

    if ! command -v npm >/dev/null 2>&1; then
        log_error "npm is not installed. Please install npm (usually comes with Node.js)"
        exit 1
    fi

    local node_version=$(node --version | sed 's/v//')
    if [[ "$(printf '%s\n' "$node_version" "18.0.0" | sort -V | head -n1)" != "18.0.0" ]]; then
        log_warn "Node.js version $node_version detected. Recommended: 18+"
    fi

    log_success "Node.js environment ready"

    # Check for Tesseract OCR (needed for PDF OCR functionality)
    if ! command -v tesseract >/dev/null 2>&1; then
        log_warn "Tesseract OCR not found. Installing Tesseract for PDF OCR functionality..."
        if [[ "$OSTYPE" == "linux-gnu"* ]]; then
            # Linux (Ubuntu/Debian)
            if command -v apt-get >/dev/null 2>&1; then
                run_cmd "sudo apt-get update && sudo apt-get install -y tesseract-ocr tesseract-ocr-eng" "Installing Tesseract OCR (Ubuntu/Debian)"
            elif command -v yum >/dev/null 2>&1; then
                run_cmd "sudo yum install -y tesseract" "Installing Tesseract OCR (CentOS/RHEL)"
            elif command -v dnf >/dev/null 2>&1; then
                run_cmd "sudo dnf install -y tesseract" "Installing Tesseract OCR (Fedora)"
            elif command -v pacman >/dev/null 2>&1; then
                run_cmd "sudo pacman -S --noconfirm tesseract tesseract-data-eng" "Installing Tesseract OCR (Arch Linux)"
            else
                log_warn "Could not determine package manager. Please install Tesseract OCR manually:"
                log_warn "  Ubuntu/Debian: sudo apt-get install tesseract-ocr tesseract-ocr-eng"
                log_warn "  CentOS/RHEL: sudo yum install tesseract"
                log_warn "  Fedora: sudo dnf install tesseract"
                log_warn "  Arch: sudo pacman -S tesseract tesseract-data-eng"
                log_warn "  macOS: brew install tesseract tesseract-lang"
                log_warn "  Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki"
            fi
        elif [[ "$OSTYPE" == "darwin"* ]]; then
            # macOS
            if command -v brew >/dev/null 2>&1; then
                run_cmd "brew install tesseract tesseract-lang" "Installing Tesseract OCR (macOS)"
            else
                log_warn "Homebrew not found. Please install Tesseract OCR manually:"
                log_warn "  brew install tesseract tesseract-lang"
            fi
        elif [[ "$OSTYPE" == "msys" || "$OSTYPE" == "win32" ]]; then
            # Windows
            log_warn "Tesseract OCR installation on Windows requires manual setup:"
            log_warn "  Download from: https://github.com/UB-Mannheim/tesseract/wiki"
            log_warn "  Add to PATH: C:\\Program Files\\Tesseract-OCR"
        else
            log_warn "Unsupported OS for automatic Tesseract installation. Please install manually."
        fi
    else
        log_success "Tesseract OCR is already installed"
    fi

    # Install Chromium for Puppeteer (needed for web scraping)
    log_subheader "Installing Chromium Browser"
    if ! command -v chromium-browser >/dev/null 2>&1 && ! command -v chromium >/dev/null 2>&1 && ! command -v google-chrome >/dev/null 2>&1; then
        log_info "Installing Chromium browser for web scraping functionality..."
        if [[ "$OSTYPE" == "linux-gnu"* ]]; then
            # Linux (Ubuntu/Debian)
            if command -v apt-get >/dev/null 2>&1; then
                run_cmd "sudo apt-get update && sudo apt-get install -y chromium-browser" "Installing Chromium Browser (Ubuntu/Debian)"
            elif command -v yum >/dev/null 2>&1; then
                run_cmd "sudo yum install -y chromium" "Installing Chromium Browser (CentOS/RHEL)"
            elif command -v dnf >/dev/null 2>&1; then
                run_cmd "sudo dnf install -y chromium" "Installing Chromium Browser (Fedora)"
            elif command -v pacman >/dev/null 2>&1; then
                run_cmd "sudo pacman -S --noconfirm chromium" "Installing Chromium Browser (Arch Linux)"
            else
                log_warn "Could not determine package manager. Installing Chromium with npm fallback..."
                run_cmd "cd js && npm run gcp-build" "Installing Chromium via npm (fallback)"
            fi
        elif [[ "$OSTYPE" == "darwin"* ]]; then
            # macOS
            if command -v brew >/dev/null 2>&1; then
                run_cmd "brew install --cask chromium" "Installing Chromium Browser (macOS)"
            else
                log_warn "Homebrew not found. Installing Chromium with npm fallback..."
                run_cmd "cd js && npm run gcp-build" "Installing Chromium via npm (fallback)"
            fi
        elif [[ "$OSTYPE" == "msys" || "$OSTYPE" == "win32" ]]; then
            # Windows - use npm fallback
            log_info "Installing Chromium for Windows via npm..."
            run_cmd "cd js && npm run gcp-build" "Installing Chromium via npm (Windows)"
        else
            log_warn "Unsupported OS for automatic Chromium installation. Installing with npm fallback..."
            run_cmd "cd js && npm run gcp-build" "Installing Chromium via npm (fallback)"
        fi
    else
        log_success "Chromium is already installed"
    fi

    # Check for uv (Python package manager)
    if ! command -v uv >/dev/null 2>&1; then
        log_warn "uv not found. Installing uv for faster Python package management..."
        if ! run_cmd "curl -LsSf https://astral.sh/uv/install.sh | sh" "Installing uv"; then
            log_warn "Failed to install uv automatically. Will use pip as fallback."
            USE_UV=false
            log_info "USE_UV set to: $USE_UV"
        else
            export PATH="$HOME/.cargo/bin:$PATH"
            USE_UV=true
        fi
    else
        USE_UV=true
    fi
    log_info "USE_UV is: $USE_UV"

    # Create necessary directories
    log_subheader "Creating Project Structure"
    run_cmd "mkdir -p storage logs docker js/node_modules" "Creating directories"

    # Move Dockerfile if needed
    if [ -f "Dockerfile" ] && [ ! -f "docker/Dockerfile" ]; then
        run_cmd "mv Dockerfile docker/" "Moving Dockerfile to docker directory"
    fi

    # Create default config
    if [ ! -f "config.yaml" ]; then
        cat > config.yaml << 'EOF'
url: "http://localhost:3001"
storage:
  screenshots: "./storage"
  logs: "./logs"
EOF
        log_success "Created default config.yaml"
    fi

    # Create enabled tasks file if not exists
    if [ ! -f "enabled_tasks.txt" ]; then
        touch enabled_tasks.txt
        log_success "Created enabled_tasks.txt"
    fi

    # Build Docker images
    log_subheader "Building Docker Images"
    run_cmd "docker-compose build" "Building Docker images"

    # Setup Python environment
    log_subheader "Setting up Python Environment"
    log_info "USE_UV is: $USE_UV"
    if [ "$USE_UV" = true ]; then
        run_cmd "uv venv --clear" "Creating Python virtual environment"
    else
        run_cmd "python -m venv .venv" "Creating Python virtual environment (using venv)"
    fi

    # Activate virtual environment (cross-platform)
    if [[ "$OSTYPE" == "msys" || "$OSTYPE" == "win32" ]]; then
        source .venv/Scripts/activate
    else
        source .venv/bin/activate
    fi
    log_success "Python virtual environment ready"

    # Install Python dependencies
    if [ "$USE_UV" = true ]; then
        run_cmd "uv pip install -r py/requirements.txt" "Installing Python dependencies"
    else
        run_cmd "pip install -r py/requirements.txt" "Installing Python dependencies (using pip)"
    fi

    # Install Node.js dependencies
    log_subheader "Setting up Node.js Environment"
    run_cmd "npm install --prefix js" "Installing Node.js dependencies"

    log_success "Setup complete!"
    echo -e "\n${GREEN}${SPARKLES} You're all set! Next steps:${NC}"
    echo -e "  ${CYAN}1.${NC} Start development: ${WHITE}./dearreader dev${NC}"
    echo -e "  ${CYAN}2.${NC} Run tests: ${WHITE}./dearreader test${NC}"
    echo -e "  ${CYAN}3.${NC} Open browser: ${WHITE}http://localhost:3001${NC}"
}

# Development command
cmd_dev() {
    log_header "${GEAR} Starting Development Environment"

    check_docker

    # Clean up any existing containers
    run_cmd "docker-compose down --remove-orphans" "Cleaning up existing containers"

    # Run all tests first
    echo -e "\n${YELLOW}Running end-to-end tests before starting dev environment...${NC}"
    if cmd_test "e2e"; then
        log_success "End-to-end tests passed! Starting development environment..."
    else
        log_error "End-to-end tests failed. Check the output above for details."
        echo -e "\n${YELLOW}You can run tests manually with:${NC}"
        echo -e "  ${WHITE}./dearreader test e2e${NC}"
        if [ "$FORCE" != true ]; then
            log_error "Exiting due to test failures. Use --force to continue anyway."
            exit 1
        fi
        log_warn "Continuing despite test failures (--force used)"
    fi

    # Start development environment
    run_cmd "docker-compose --profile dev up --build -d" "Starting development services"

    log_success "Development environment started!"
    echo -e "\n${GREEN}${HEART} Services are running:${NC}"
    echo -e "  ${CYAN}‚Ä¢${NC} Web Interface: ${WHITE}http://localhost:3001${NC}"
    echo -e "  ${CYAN}‚Ä¢${NC} API Endpoint: ${WHITE}http://localhost:3001/https://www.ala.org${NC}"
    echo -e "  ${CYAN}‚Ä¢${NC} View logs: ${WHITE}./dearreader logs${NC}"

    # Show logs if requested
    if [ "$FOLLOW" = true ]; then
        echo -e "\n${YELLOW}Following logs (Ctrl+C to exit)...${NC}"
        docker-compose logs -f js-functions python
    fi
}

# Test command
cmd_test() {
    local test_type="${1:-all}"
    log_header "${TEST} Running Tests ($test_type)"

    case "$test_type" in
        js)
            run_cmd "docker-compose --profile dev run --rm js-test" "Running JavaScript tests" true
            ;;
        python)
            if ! command -v uv >/dev/null 2>&1 && ! command -v python >/dev/null 2>&1; then
                log_error "Neither uv nor python found. Please run setup first"
                exit 1
            fi
            if command -v uv >/dev/null 2>&1; then
                run_cmd "uv run py/app.py tests --verbose" "Running Python tests" true
            else
                run_cmd "python py/app.py tests --verbose" "Running Python tests (using python)" true
            fi
            ;;
        e2e)
            log_subheader "Running End-to-End Tests"
            if run_cmd "./scripts/e2e-test.sh" "Running end-to-end tests" true; then
                log_success "End-to-end tests passed"
            else
                log_error "End-to-end tests failed"
                [ "$FORCE" != true ] && exit 1
            fi
            ;;
        all)
            log_subheader "Running JavaScript Tests (excluding AI/LLM)"
            # Run JS tests but exclude AI/LLM related tests to avoid burning API requests
            if run_cmd "docker-compose --profile dev run --rm js-test npm run test:no-ai" "Running JavaScript tests (excluding AI)" true; then
                log_success "JavaScript tests passed"
            else
                log_error "JavaScript tests failed"
                [ "$FORCE" != true ] && exit 1
            fi

            log_subheader "Running Python Tests"
            if command -v uv >/dev/null 2>&1; then
                if run_cmd "uv run py/app.py tests --verbose" "Running Python tests" true; then
                    log_success "Python tests passed"
                else
                    log_error "Python tests failed"
                    [ "$FORCE" != true ] && exit 1
                fi
            elif command -v python >/dev/null 2>&1; then
                if run_cmd "python py/app.py tests --verbose" "Running Python tests (using python)" true; then
                    log_success "Python tests passed"
                else
                    log_error "Python tests failed"
                    [ "$FORCE" != true ] && exit 1
                fi
            else
                log_warn "Neither uv nor python found, skipping Python tests"
            fi

            log_subheader "Running End-to-End Tests"
            if run_cmd "./scripts/e2e-test.sh" "Running end-to-end tests" true; then
                log_success "End-to-end tests passed"
            else
                log_error "End-to-end tests failed"
                [ "$FORCE" != true ] && exit 1
            fi

            log_success "All tests completed!"
            ;;
        pipeline)
            cmd_test_pipeline
            ;;
        *)
            log_error "Unknown test type: $test_type"
            echo "Available: js, python, e2e, pipeline, all"
            exit 1
            ;;
    esac
}

# Run command
cmd_run() {
    local env="${1:-dev}"
    log_header "${ROCKET} Starting $env Environment"

    check_docker

    case "$env" in
        dev)
            run_cmd "docker-compose down --remove-orphans" "Cleaning up containers"
            run_cmd "docker-compose --profile dev up --build -d" "Starting development environment"
            log_success "Development environment started"
            log_info "View logs with: ./dearreader logs -F"
            ;;
        prod)
            run_cmd "docker-compose down --remove-orphans" "Cleaning up containers"
            run_cmd "docker-compose --profile prod up --build -d" "Starting production environment"
            log_success "Production environment started"
            log_info "Services running in background"
            ;;
        *)
            log_error "Unknown environment: $env"
            echo "Available: dev, prod"
            exit 1
            ;;
    esac
}

# Stop command
cmd_stop() {
    log_header "${STOP} Stopping Services"
    run_cmd "docker-compose down --remove-orphans" "Stopping all containers"
    log_success "All services stopped"
}

# Status command
cmd_status() {
    log_header "${INFO} System Status"

    echo -e "\n${BOLD}Docker Services:${NC}"
    if command -v docker >/dev/null 2>&1 && docker version >/dev/null 2>&1; then
        docker-compose ps
    else
        log_warn "Docker not available"
    fi

    echo -e "\n${BOLD}API Health Check:${NC}"
    if curl -s http://localhost:3001/health >/dev/null 2>&1; then
        log_success "API is healthy"
    else
        log_warn "API not responding (services may not be running)"
    fi

    echo -e "\n${BOLD}Project Structure:${NC}"
    for dir in storage logs docker js/node_modules; do
        if [ -d "$dir" ]; then
            echo -e "  ${GREEN}${CHECK}${NC} $dir"
        else
            echo -e "  ${RED}${CROSS}${NC} $dir"
        fi
    done

    echo -e "\n${BOLD}Configuration:${NC}"
    if [ -f "config.yaml" ]; then
        echo -e "  ${GREEN}${CHECK}${NC} config.yaml"
    else
        echo -e "  ${RED}${CROSS}${NC} config.yaml"
    fi

    echo -e "\n${BOLD}Environment Variables (.env):${NC}"
    if [ -f ".env" ]; then
        echo -e "  ${GREEN}${CHECK}${NC} .env file exists"
        # List set variables (non-empty lines starting with letters, ignoring comments)
        local env_vars=$(grep -E '^[A-Z_][A-Z0-9_]*=' .env | sed 's/=.*//' | tr '\n' ' ')
        if [ -n "$env_vars" ]; then
            echo -e "  ${CYAN}Set variables:${NC} $env_vars"
        else
            echo -e "  ${YELLOW}${WARNING}${NC} No variables set in .env"
        fi
    else
        echo -e "  ${RED}${CROSS}${NC} .env file not found"
    fi

    echo -e "\n${BOLD}Pipeline Configuration:${NC}"
    if [ -f "crawl_pipeline.yaml" ]; then
        echo -e "  ${GREEN}${CHECK}${NC} crawl_pipeline.yaml"
    else
        echo -e "  ${RED}${CROSS}${NC} crawl_pipeline.yaml"
    fi
}

# Logs command
cmd_logs() {
    log_header "${BOOK} Service Logs"

    if [ "$FOLLOW" = true ]; then
        docker-compose logs -f
    else
        docker-compose logs
    fi
}

# Clean command
cmd_clean() {
    log_header "${WARNING} Cleaning Up"

    log_warn "This will remove all containers, volumes, and cached images"
    read -p "Are you sure? (y/N): " -n 1 -r
    echo

    if [[ $REPLY =~ ^[Yy]$ ]]; then
        run_cmd "docker-compose down --remove-orphans" "Stopping containers"
        run_cmd "docker-compose down --volumes --remove-orphans" "Removing volumes"
        run_cmd "docker system prune -f" "Cleaning Docker system"
        run_cmd "rm -rf storage/* logs/*" "Cleaning local storage"
        log_success "Cleanup complete"
    else
        log_info "Cleanup cancelled"
    fi
}

# API test command
cmd_api() {
    local action="${1:-test}"
    log_header "${DOCKER} API Testing"

    case "$action" in
        test)
            echo -e "\n${BOLD}Testing API endpoints...${NC}"

            # Test basic health
            if curl -s http://localhost:3001/health >/dev/null 2>&1; then
                log_success "Health check passed"
            else
                log_error "Health check failed"
            fi

            # Test content extraction
            echo -e "\n${BOLD}Testing content extraction:${NC}"
            echo -e "  ${CYAN}ALA Website:${NC}"
            curl -s "http://localhost:3001/https://www.ala.org" | head -5

            echo -e "\n  ${CYAN}Wikipedia Reading:${NC}"
            curl -s "http://localhost:3001/https://en.wikipedia.org/wiki/Reading" | head -5

            # Test JSON response
            echo -e "\n${BOLD}Testing JSON response:${NC}"
            curl -s -H "Accept: application/json" "http://localhost:3001/https://worldliteracyfoundation.org" | jq '.data.title' 2>/dev/null || echo "  JSON parsing failed"
            ;;
        *)
            log_error "Unknown API action: $action"
            echo "Available: test"
            exit 1
            ;;
    esac
}

# Task command
cmd_task() {
    local subcommand="${1:-list}"
    local task_name="$2"
    log_header "${BOOK} Pipeline Tasks"

    case "$subcommand" in
        list)
            log_subheader "Listing Available Tasks"

            if [ ! -f "crawl_pipeline.yaml" ]; then
                log_error "crawl_pipeline.yaml not found. Please ensure the pipeline configuration exists."
                exit 1
            fi

            if ! command -v node >/dev/null 2>&1; then
                log_error "Node.js is not available. Please run setup first."
                exit 1
            fi

            # Use Node.js to parse YAML and list tasks
            run_cmd "cd js && node -e \"
const yaml = require('js-yaml');
const fs = require('fs');
const path = require('path');

try {
    const configPath = path.join('..', 'crawl_pipeline.yaml');
    const configContent = fs.readFileSync(configPath, 'utf8');
    const config = yaml.load(configContent);

    console.log('üìã Available Pipeline Tasks:');
    console.log('');

    if (config.pipeline_tests && config.pipeline_tests.stage_tests) {
        console.log('üîß Stage Tasks:');
        Object.entries(config.pipeline_tests.stage_tests).forEach(([key, value]) => {
            console.log(\`  ‚Ä¢ \${key}: \${value.name || 'Unnamed'}\`);
        });
        console.log('');
    }

    if (config.pipeline_tests && config.pipeline_tests.pipeline_tests) {
        console.log('üîÑ Pipeline Tasks:');
        Object.entries(config.pipeline_tests.pipeline_tests).forEach(([key, value]) => {
            console.log(\`  ‚Ä¢ \${key}: \${value.name || 'Unnamed'}\`);
        });
        console.log('');
    }

    if (config.pipeline_tests && config.pipeline_tests.ai_task_tests) {
        console.log('ü§ñ AI Tasks:');
        Object.entries(config.pipeline_tests.ai_task_tests).forEach(([key, value]) => {
            console.log(\`  ‚Ä¢ \${key}: \${value.name || 'Unnamed'}\`);
        });
        console.log('');
    }

    if (!config.pipeline_tests ||
        (!config.pipeline_tests.stage_tests && !config.pipeline_tests.pipeline_tests && !config.pipeline_tests.ai_task_tests)) {
        console.log('No tasks found in pipeline configuration.');
    }
} catch (error) {
    console.error('Error parsing pipeline configuration:', error.message);
    process.exit(1);
}
\"" "Listing pipeline tasks" true
            ;;
        status)
            log_subheader "Task Status"

            if [ ! -f "crawl_pipeline.yaml" ]; then
                log_error "crawl_pipeline.yaml not found. Please ensure the pipeline configuration exists."
                exit 1
            fi

            if ! command -v node >/dev/null 2>&1; then
                log_error "Node.js is not available. Please run setup first."
                exit 1
            fi

            # Create enabled_tasks.txt if not exists
            if [ ! -f "enabled_tasks.txt" ]; then
                touch enabled_tasks.txt
            fi

            # Use Node.js to parse YAML and show status
            run_cmd "cd js && node -e \"
const yaml = require('js-yaml');
const fs = require('fs');
const path = require('path');

try {
    const configPath = path.join('..', 'crawl_pipeline.yaml');
    const configContent = fs.readFileSync(configPath, 'utf8');
    const config = yaml.load(configContent);
    const enabledPath = path.join('..', 'enabled_tasks.txt');
    const enabledContent = fs.readFileSync(enabledPath, 'utf8');
    const enabledTasks = new Set(enabledContent.split('\n').filter(line => line.trim()));

    console.log('üìã Pipeline Task Status:');
    console.log('');

    let hasTasks = false;

    if (config.pipeline_tests && config.pipeline_tests.stage_tests) {
        console.log('üîß Stage Tasks:');
        Object.entries(config.pipeline_tests.stage_tests).forEach(([key, value]) => {
            const status = enabledTasks.has(key) ? '‚úÖ Enabled' : '‚ùå Disabled';
            console.log(\`  ‚Ä¢ \${key}: \${value.name || 'Unnamed'} [\${status}]\`);
        });
        console.log('');
        hasTasks = true;
    }

    if (config.pipeline_tests && config.pipeline_tests.pipeline_tests) {
        console.log('üîÑ Pipeline Tasks:');
        Object.entries(config.pipeline_tests.pipeline_tests).forEach(([key, value]) => {
            const status = enabledTasks.has(key) ? '‚úÖ Enabled' : '‚ùå Disabled';
            console.log(\`  ‚Ä¢ \${key}: \${value.name || 'Unnamed'} [\${status}]\`);
        });
        console.log('');
        hasTasks = true;
    }

    if (config.pipeline_tests && config.pipeline_tests.ai_task_tests) {
        console.log('ü§ñ AI Tasks:');
        Object.entries(config.pipeline_tests.ai_task_tests).forEach(([key, value]) => {
            const status = enabledTasks.has(key) ? '‚úÖ Enabled' : '‚ùå Disabled';
            console.log(\`  ‚Ä¢ \${key}: \${value.name || 'Unnamed'} [\${status}]\`);
        });
        console.log('');
        hasTasks = true;
    }

    if (!hasTasks) {
        console.log('No tasks found in pipeline configuration.');
    }
} catch (error) {
    console.error('Error parsing pipeline configuration:', error.message);
    process.exit(1);
}
\"" "Showing task status" true
            ;;
        enable)
            if [ -z "$task_name" ]; then
                log_error "Task name is required for enable command."
                echo "Usage: ./dearreader task enable <task_name>"
                exit 1
            fi

            if [ ! -f "crawl_pipeline.yaml" ]; then
                log_error "crawl_pipeline.yaml not found. Please ensure the pipeline configuration exists."
                exit 1
            fi

            if ! command -v node >/dev/null 2>&1; then
                log_error "Node.js is not available. Please run setup first."
                exit 1
            fi

            # Create enabled_tasks.txt if not exists
            if [ ! -f "enabled_tasks.txt" ]; then
                touch enabled_tasks.txt
            fi

            # Check if task exists
            if ! run_cmd "cd js && node -e \"
const yaml = require('js-yaml');
const fs = require('fs');
const path = require('path');

try {
    const configPath = path.join('..', 'crawl_pipeline.yaml');
    const configContent = fs.readFileSync(configPath, 'utf8');
    const config = yaml.load(configContent);

    const taskName = process.argv[1];
    let found = false;

    if (config.pipeline_tests && config.pipeline_tests.stage_tests && config.pipeline_tests.stage_tests[taskName]) found = true;
    if (config.pipeline_tests && config.pipeline_tests.pipeline_tests && config.pipeline_tests.pipeline_tests[taskName]) found = true;
    if (config.pipeline_tests && config.pipeline_tests.ai_task_tests && config.pipeline_tests.ai_task_tests[taskName]) found = true;

    if (!found) {
        console.error('Task not found:', taskName);
        process.exit(1);
    }
} catch (error) {
    console.error('Error:', error.message);
    process.exit(1);
}
\" \"$task_name\"" "Checking if task exists" >/dev/null 2>&1; then
                log_error "Task '$task_name' not found in pipeline configuration."
                exit 1
            fi

            # Enable the task
            if grep -q "^$task_name$" enabled_tasks.txt; then
                log_warn "Task '$task_name' is already enabled."
            else
                echo "$task_name" >> enabled_tasks.txt
                log_success "Task '$task_name' enabled."
            fi
            ;;
        disable)
            if [ -z "$task_name" ]; then
                log_error "Task name is required for disable command."
                echo "Usage: ./dearreader task disable <task_name>"
                exit 1
            fi

            if [ ! -f "enabled_tasks.txt" ]; then
                log_warn "No tasks are currently enabled."
                exit 0
            fi

            # Disable the task
            if grep -q "^$task_name$" enabled_tasks.txt; then
                sed -i "/^$task_name$/d" enabled_tasks.txt
                log_success "Task '$task_name' disabled."
            else
                log_warn "Task '$task_name' is not enabled."
            fi
            ;;
        *)
            log_error "Unknown task subcommand: $subcommand"
            echo "Available: list, status, enable, disable"
            exit 1
            ;;
    esac
}

# Test pipeline command
cmd_test_pipeline() {
    log_header "${TEST} Running Pipeline Tests"

    # Check if Node.js environment is available
    if ! command -v node >/dev/null 2>&1; then
        log_error "Node.js is not available. Pipeline tests require Node.js."
        exit 1
    fi

    # Check if the pipeline test configuration exists
    if [ ! -f "crawl_pipeline.yaml" ]; then
        log_error "crawl_pipeline.yaml not found. Pipeline tests require this configuration file."
        exit 1
    fi

    # Check if the pipeline test script exists
    if [ ! -f "js/src/test-pipeline.js" ]; then
        log_info "Creating pipeline test script..."
        cat > js/src/test-pipeline.js << 'EOF'
#!/usr/bin/env node

/**
 * Pipeline Test Runner
 * Tests all pipeline features defined in crawl_pipeline.yaml
 * Uses mock data and responses to avoid external API calls
 */

const fs = require('fs');
const path = require('path');
const yaml = require('js-yaml');
const { fileURLToPath } = require('url');

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Colors for output
const colors = {
    reset: '\x1b[0m',
    red: '\x1b[31m',
    green: '\x1b[32m',
    yellow: '\x1b[33m',
    blue: '\x1b[34m',
    magenta: '\x1b[35m',
    cyan: '\x1b[36m',
    white: '\x1b[37m'
};

function log(color, message) {
    console.log(`${color}${message}${colors.reset}`);
}

function logTest(testName, status, details = '') {
    const statusColor = status === 'PASS' ? colors.green : status === 'FAIL' ? colors.red : colors.yellow;
    const statusIcon = status === 'PASS' ? '‚úÖ' : status === 'FAIL' ? '‚ùå' : '‚ö†Ô∏è';
    console.log(`${statusColor}${statusIcon} ${testName}${colors.reset}${details ? ` - ${details}` : ''}`);
}

// Mock implementations for pipeline stages
class MockCrawler {
    static async crawl(url, config) {
        log(colors.blue, `üîç Mock crawling: ${url}`);

        // Simulate different response types based on URL
        if (url.includes('html')) {
            return {
                content: '<html><body><h1>Test Article</h1><p>This is test content.</p></body></html>',
                contentType: 'text/html',
                statusCode: 200,
                headers: { 'content-type': 'text/html' }
            };
        } else if (url.includes('json')) {
            return {
                content: JSON.stringify({ title: 'Test JSON', data: 'test content' }),
                contentType: 'application/json',
                statusCode: 200,
                headers: { 'content-type': 'application/json' }
            };
        }

        return {
            content: 'Default mock content',
            contentType: 'text/plain',
            statusCode: 200,
            headers: { 'content-type': 'text/plain' }
        };
    }
}

class MockTextExtractor {
    static extractText(html) {
        log(colors.cyan, `üìù Mock extracting text from HTML`);

        // Simple HTML to text conversion
        const text = html
            .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
            .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
            .replace(/<[^>]+>/g, ' ')
            .replace(/\s+/g, ' ')
            .trim();

        return {
            text: text,
            wordCount: text.split(' ').length,
            paragraphs: text.split(/[.!?]+/).filter(p => p.trim().length > 0)
        };
    }
}

class MockContentFilter {
    static filter(content, config) {
        log(colors.yellow, `üîß Mock filtering content`);

        let filtered = content;

        // Apply filters based on config
        if (config.min_content_length && filtered.length < config.min_content_length) {
            return { filtered: '', removed: true, reason: 'too short' };
        }

        if (config.remove_duplicates) {
            // Simple deduplication
            const sentences = filtered.split(/[.!?]+/);
            const unique = [...new Set(sentences.map(s => s.trim()))];
            filtered = unique.join('. ') + '.';
        }

        return {
            filtered: filtered,
            removed: false,
            stats: { originalLength: content.length, filteredLength: filtered.length }
        };
    }
}

class MockJSONFormatter {
    static format(data, config) {
        log(colors.magenta, `üìã Mock formatting as JSON`);

        const result = {
            success: true,
            timestamp: new Date().toISOString(),
            data: data,
            metadata: {
                processing_time_ms: Math.random() * 1000,
                version: '1.0.0'
            }
        };

        // Add optional fields based on config
        if (config.include_url) result.url = data.url || 'mock://test';
        if (config.include_processing_stats) result.processing_stats = result.metadata;

        return result;
    }
}

class MockPDFExtractor {
    static async extractText(buffer) {
        log(colors.red, `üìÑ Mock extracting text from PDF`);

        // Mock PDF text extraction
        if (buffer.length === 0) {
            throw new Error('Failed to extract text from PDF: Empty buffer');
        }

        return {
            text: 'This is mock extracted text from a PDF document.',
            pageCount: 1,
            metadata: {
                title: 'Mock PDF Document',
                author: 'Test Author',
                pages: 1
            }
        };
    }
}

// Test runner class
class PipelineTestRunner {
    constructor() {
        this.results = { passed: 0, failed: 0, skipped: 0 };
        this.testConfig = null;
    }

    async loadConfig() {
        try {
            const configPath = path.join(__dirname, '../../crawl_pipeline.yaml');
            const configContent = fs.readFileSync(configPath, 'utf8');
            this.testConfig = yaml.load(configContent);
            log(colors.green, '‚úÖ Loaded pipeline configuration');
        } catch (error) {
            log(colors.red, `‚ùå Failed to load configuration: ${error.message}`);
            throw error;
        }
    }

    async runStageTests() {
        log(colors.blue, '\nüß™ Running Stage Tests');

        if (!this.testConfig.pipeline_tests?.stage_tests) {
            log(colors.yellow, '‚ö†Ô∏è No stage tests defined, skipping');
            return;
        }

        for (const [stageType, stageConfig] of Object.entries(this.testConfig.pipeline_tests.stage_tests)) {
            log(colors.cyan, `\nüìã Testing ${stageConfig.name}`);

            for (const test of stageConfig.tests) {
                try {
                    await this.runStageTest(stageType, test);
                } catch (error) {
                    logTest(`${stageType}:${test.name}`, 'FAIL', error.message);
                    this.results.failed++;
                }
            }
        }
    }

    async runStageTest(stageType, test) {
        switch (stageType) {
            case 'crawl':
                await this.testCrawlStage(test);
                break;
            case 'text_extract':
                await this.testTextExtractStage(test);
                break;
            case 'content_filter':
                await this.testContentFilterStage(test);
                break;
            case 'json_format':
                await this.testJSONFormatStage(test);
                break;
            case 'pdf_extract':
                await this.testPDFExtractStage(test);
                break;
            default:
                logTest(`${stageType}:${test.name}`, 'SKIP', 'Unknown stage type');
                this.results.skipped++;
        }
    }

    async testCrawlStage(test) {
        const result = await MockCrawler.crawl(test.test_url, test);

        let passed = true;
        let details = [];

        if (test.expected_content_type && result.contentType !== test.expected_content_type) {
            passed = false;
            details.push(`Expected content-type: ${test.expected_content_type}, got: ${result.contentType}`);
        }

        if (test.expected_selectors && test.test_url.includes('html')) {
            for (const selector of test.expected_selectors) {
                if (!result.content.includes(`<${selector}>`)) {
                    passed = false;
                    details.push(`Missing expected selector: ${selector}`);
                }
            }
        }

        if (passed) {
            logTest(`crawl:${test.name}`, 'PASS');
            this.results.passed++;
        } else {
            logTest(`crawl:${test.name}`, 'FAIL', details.join(', '));
            this.results.failed++;
        }
    }

    async testTextExtractStage(test) {
        const result = MockTextExtractor.extractText(test.test_html);

        let passed = true;
        let details = [];

        for (const expected of test.expected_text_contains || []) {
            if (!result.text.includes(expected)) {
                passed = false;
                details.push(`Missing expected text: "${expected}"`);
            }
        }

        for (const excluded of test.expected_text_excludes || []) {
            if (result.text.includes(excluded)) {
                passed = false;
                details.push(`Found unexpected text: "${excluded}"`);
            }
        }

        if (passed) {
            logTest(`text_extract:${test.name}`, 'PASS');
            this.results.passed++;
        } else {
            logTest(`text_extract:${test.name}`, 'FAIL', details.join(', '));
            this.results.failed++;
        }
    }

    async testContentFilterStage(test) {
        const result = MockContentFilter.filter(test.test_content, test);

        let passed = true;
        let details = [];

        if (test.expected_filtered && !result.removed) {
            passed = false;
            details.push('Expected content to be filtered but it was not');
        }

        if (test.expected_content && result.filtered !== test.expected_content) {
            passed = false;
            details.push('Filtered content does not match expected result');
        }

        if (passed) {
            logTest(`content_filter:${test.name}`, 'PASS');
            this.results.passed++;
        } else {
            logTest(`content_filter:${test.name}`, 'FAIL', details.join(', '));
            this.results.failed++;
        }
    }

    async testJSONFormatStage(test) {
        const result = MockJSONFormatter.format(test.test_data, test);

        let passed = true;
        let details = [];

        for (const field of test.expected_fields || []) {
            if (!(field in result)) {
                passed = false;
                details.push(`Missing expected field: ${field}`);
            }
        }

        for (const field of test.expected_nested_fields || []) {
            const keys = field.split('.');
            let value = result;
            for (const key of keys) {
                value = value?.[key];
            }
            if (value === undefined) {
                passed = false;
                details.push(`Missing expected nested field: ${field}`);
            }
        }

        if (passed) {
            logTest(`json_format:${test.name}`, 'PASS');
            this.results.passed++;
        } else {
            logTest(`json_format:${test.name}`, 'FAIL', details.join(', '));
            this.results.failed++;
        }
    }

    async testPDFExtractStage(test) {
        try {
            const buffer = Buffer.from(test.test_pdf_content || '', 'utf8');
            const result = await MockPDFExtractor.extractText(buffer);

            let passed = true;
            let details = [];

            if (test.expected_error) {
                passed = false;
                details.push('Expected error but got successful result');
            }

            for (const expected of test.expected_text_contains || []) {
                if (!result.text.includes(expected)) {
                    passed = false;
                    details.push(`Missing expected text: "${expected}"`);
                }
            }

            if (passed) {
                logTest(`pdf_extract:${test.name}`, 'PASS');
                this.results.passed++;
            } else {
                logTest(`pdf_extract:${test.name}`, 'FAIL', details.join(', '));
                this.results.failed++;
            }
        } catch (error) {
            if (test.expected_error && error.message.includes(test.expected_error)) {
                logTest(`pdf_extract:${test.name}`, 'PASS');
                this.results.passed++;
            } else {
                logTest(`pdf_extract:${test.name}`, 'FAIL', error.message);
                this.results.failed++;
            }
        }
    }

    async runPipelineTests() {
        log(colors.blue, '\nüîß Running Pipeline Tests');

        if (!this.testConfig.pipeline_tests?.pipeline_tests) {
            log(colors.yellow, '‚ö†Ô∏è No pipeline tests defined, skipping');
            return;
        }

        for (const [pipelineName, pipelineConfig] of Object.entries(this.testConfig.pipeline_tests.pipeline_tests)) {
            log(colors.cyan, `\nüìã Testing Pipeline: ${pipelineConfig.name}`);

            try {
                const result = await this.testPipeline(pipelineName, pipelineConfig);
                if (result.passed) {
                    logTest(`pipeline:${pipelineName}`, 'PASS');
                    this.results.passed++;
                } else {
                    logTest(`pipeline:${pipelineName}`, 'FAIL', result.details.join(', '));
                    this.results.failed++;
                }
            } catch (error) {
                logTest(`pipeline:${pipelineName}`, 'FAIL', error.message);
                this.results.failed++;
            }
        }
    }

    async testPipeline(pipelineName, config) {
        // Mock pipeline execution
        const result = {
            passed: true,
            details: []
        };

        // Check if all expected fields are present in mock result
        const mockResult = {
            title: 'Mock Article',
            content: 'Mock content',
            links: [],
            metadata: {},
            timestamp: new Date().toISOString()
        };

        for (const field of config.expected_fields || []) {
            if (!(field in mockResult)) {
                result.passed = false;
                result.details.push(`Missing expected field: ${field}`);
            }
        }

        // Validate output format
        if (config.expected_output_format === 'json') {
            try {
                JSON.stringify(mockResult);
            } catch (error) {
                result.passed = false;
                result.details.push('Invalid JSON format');
            }
        }

        return result;
    }

    async runAITaskTests() {
        log(colors.blue, '\nü§ñ Running AI Task Tests (Mocked)');

        if (!this.testConfig.pipeline_tests?.ai_task_tests) {
            log(colors.yellow, '‚ö†Ô∏è No AI task tests defined, skipping');
            return;
        }

        for (const [taskName, taskConfig] of Object.entries(this.testConfig.pipeline_tests.ai_task_tests)) {
            log(colors.cyan, `\nüìã Testing AI Task: ${taskConfig.name}`);

            try {
                const result = await this.testAITask(taskName, taskConfig);
                if (result.passed) {
                    logTest(`ai_task:${taskName}`, 'PASS');
                    this.results.passed++;
                } else {
                    logTest(`ai_task:${taskName}`, 'FAIL', result.details.join(', '));
                    this.results.failed++;
                }
            } catch (error) {
                logTest(`ai_task:${taskName}`, 'FAIL', error.message);
                this.results.failed++;
            }
        }
    }

    async testAITask(taskName, config) {
        const result = {
            passed: true,
            details: []
        };

        // Mock AI task execution (no real API calls)
        const mockResponse = config.mock_response || 'Mock AI response';

        // Validate task routing
        if (config.validate_task_routing) {
            const expectedProvider = config.expected_provider;
            if (expectedProvider) {
                // In a real implementation, this would check if the task routes to the correct provider
                log(colors.blue, `üîÑ Mock routing task ${taskName} to provider: ${expectedProvider}`);
            }
        }

        // Validate response format
        if (config.expected_response_format === 'json') {
            try {
                JSON.parse(mockResponse);
            } catch (error) {
                result.passed = false;
                result.details.push('Invalid JSON response format');
            }
        }

        return result;
    }

    printSummary() {
        const total = this.results.passed + this.results.failed + this.results.skipped;

        log(colors.blue, '\nüìä Test Summary');
        console.log(`Total Tests: ${total}`);
        console.log(`${colors.green}Passed: ${this.results.passed}${colors.reset}`);
        console.log(`${colors.red}Failed: ${this.results.failed}${colors.reset}`);
        console.log(`${colors.yellow}Skipped: ${this.results.skipped}${colors.reset}`);

        if (this.results.failed === 0) {
            log(colors.green, '\nüéâ All pipeline tests passed!');
            return 0;
        } else {
            log(colors.red, '\n‚ùå Some pipeline tests failed!');
            return 1;
        }
    }

    async run() {
        try {
            log(colors.magenta, 'üöÄ Starting Pipeline Tests');

            await this.loadConfig();

            // Run all test categories
            await this.runStageTests();
            await this.runPipelineTests();
            await this.runAITaskTests();

            return this.printSummary();

        } catch (error) {
            log(colors.red, `‚ùå Pipeline tests failed: ${error.message}`);
            return 1;
        }
    }
}

// Run the tests
const runner = new PipelineTestRunner();
runner.run().then(exitCode => {
    process.exit(exitCode);
}).catch(error => {
    log(colors.red, `‚ùå Unexpected error: ${error.message}`);
    process.exit(1);
});
EOF
        log_success "Created pipeline test script"
    fi

    # Run the pipeline tests
    log_subheader "Running Pipeline Tests"
    if run_cmd "cd js && node src/test-pipeline.js" "Running pipeline tests" true; then
        log_success "Pipeline tests passed"
    else
        log_error "Pipeline tests failed"
        [ "$FORCE" != true ] && exit 1
    fi
}

# Migration command
cmd_migration() {
    echo -e "  ${GREEN}${CHECK}${NC} ./dearreader script created and working"
    echo -e "  ${GREEN}${CHECK}${NC} All functionality from old scripts preserved"
    echo -e "  ${GREEN}${CHECK}${NC} Enhanced with new features (status, logs, api test)"

    echo -e "\n${BOLD}üìã Old Scripts Status:${NC}"
    OLD_SCRIPTS=("setup.sh" "dev.sh" "run.sh")
    for script in "${OLD_SCRIPTS[@]}"; do
        if [ -f "$script" ]; then
            echo -e "  ${YELLOW}${WARNING}${NC} $script (deprecated, has migration notice)"
        else
            echo -e "  ${GREEN}${CHECK}${NC} $script (removed)"
        fi
    done

    echo -e "\n${BOLD}üîÑ Migration Commands:${NC}"
    echo -e "  ${CYAN}Old:${NC} ./setup.sh ${WHITE}‚Üí${NC} ${GREEN}New:${NC} ./dearreader setup"
    echo -e "  ${CYAN}Old:${NC} ./dev.sh ${WHITE}‚Üí${NC} ${GREEN}New:${NC} ./dearreader dev"
    echo -e "  ${CYAN}Old:${NC} ./run.sh test all ${WHITE}‚Üí${NC} ${GREEN}New:${NC} ./dearreader test all"

    echo -e "\n${BOLD}üÜï New Features:${NC}"
    echo -e "  ${MAGENTA}‚Ä¢${NC} ./dearreader status - System health check"
    echo -e "  ${MAGENTA}‚Ä¢${NC} ./dearreader logs -F - Follow logs in real-time"
    echo -e "  ${MAGENTA}‚Ä¢${NC} ./dearreader api test - Test API endpoints"
    echo -e "  ${MAGENTA}‚Ä¢${NC} ./dearreader clean - Safe cleanup"

    echo -e "\n${BOLD}üìö For detailed migration guide:${NC}"
    echo -e "  cat docs/migration.md"

    echo -e "\n${BOLD}üßπ To clean up old files:${NC}"
    echo -e "  ./scripts/cleanup.sh"
}

# Main logic
main() {
    local command="$1"
    shift || true

    # Parse flags
    VERBOSE=false
    FORCE=false
    FOLLOW=false

    local args_without_flags=()
    for arg in "$@"; do
        case "$arg" in
            --verbose|-v) VERBOSE=true ;;
            --force|-f) FORCE=true ;;
            --follow|-F) FOLLOW=true ;;
            *) args_without_flags+=("$arg") ;;
        esac
    done
    set -- "${args_without_flags[@]}"

    # Handle commands
    case "$command" in
        setup)
            cmd_setup
            ;;
        dev)
            cmd_dev
            ;;
        test)
            cmd_test "$1"
            ;;
        run)
            cmd_run "$1"
            ;;
        stop)
            cmd_stop
            ;;
        status)
            cmd_status
            ;;
        logs)
            cmd_logs
            ;;
        clean)
            cmd_clean
            ;;
        api)
            cmd_api "$1"
            ;;
        task)
            cmd_task "$1" "$2"
            ;;
        migration)
            cmd_migration
            ;;
        help|--help|-h|"")
            show_help
            exit 0
            ;;
        *)
            log_error "Unknown command: $command"
            echo
            show_help
            exit 1
            ;;
    esac
}

# Run main with all arguments
main "$@"
